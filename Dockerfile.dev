# Use base image with Python and Apache Spark pre-installed
FROM python:3.9-slim


# Build container as root
USER root


# Install Hadoop and Java
RUN apt-get update
RUN apt-get install -y openjdk-17-jdk
RUN apt-get install -y wget 
RUN apt-get install -y ssh 
RUN apt-get install -y curl

COPY bin/hadoop-3.4.0.tar.gz hadoop-3.4.0.tar.gz
RUN tar -xvzf hadoop-3.4.0.tar.gz
RUN mv hadoop-3.4.0 /usr/local/hadoop
ENV HADOOP_HOME /usr/local/hadoop
ENV JAVA_HOME /usr/lib/jvm/java-17-openjdk-arm64
ENV PATH $JAVA_HOME/bin:$HADOOP_HOME/bin:$PATH


# Install Spark, Jupyter, etc.py
COPY requirements.dev.txt requirements.dev.txt
RUN pip install -r requirements.dev.txt
EXPOSE 8888
ENV PYSPARK_PYTHON=python
ENV PYSPARK_DRIVER_PYTHON=python


# Install VSCode Extensions
RUN wget -qO- https://github.com/cdr/code-server/archive/v4.90.3.tar.gz | tar xz
RUN mv code-server-4.90.3 /opt/code-server
RUN /opt/code-server/install.sh ms-python.python
RUN /opt/code-server/install.sh ms-toolsai.jupyter
EXPOSE 22

# Copy the main.py file into the container and run as user
COPY src/ /app/
WORKDIR /app

ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

CMD ["python", "main.py"]
